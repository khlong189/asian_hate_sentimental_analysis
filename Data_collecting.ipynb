{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1_okEn_4RCFcJBCu4hVWxEdl3g2pzG_En","authorship_tag":"ABX9TyNJMK+xDKaKe0MEheVmgtY3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Set-up:"],"metadata":{"id":"oGrWbmCkmsGL"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFzq2B-AMmLO","executionInfo":{"status":"ok","timestamp":1673800417632,"user_tz":300,"elapsed":6625,"user":{"displayName":"Khanh Long Nguyen","userId":"01997719433341092319"}},"outputId":"5238a336-95a6-4dcb-85c8-e1b404b23eb8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","os.chdir('/content/drive/MyDrive/NLP project ')"],"metadata":{"id":"5TaTIv63fYOE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Libraries:"],"metadata":{"id":"XFefDApNmv25"}},{"cell_type":"code","source":["#!pip install snscrape"],"metadata":{"id":"bBA30lncxaaO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import snscrape.modules.twitter as sntwitter\n","import pandas as pd"],"metadata":{"id":"u3waDGAAfU7V"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Scraping Tweets using `snsscrape` library:"],"metadata":{"id":"FucPl-CclUTp"}},{"cell_type":"markdown","source":["**OBJECTIVE:** Scraping 10,000 tweets on the topic of Asian racism during COVID-19 pandemic period with the minimum likes of at least 50\n","\n","- References: https://github.com/JustAnotherArchivist/snscrape/\n","- Hashtags I will be looking for: #chinesevirus, #StopAAPIHate, #AtlantaShooting, #StopAsianHateCrimes, #ChinaLiedPeopleDied\n","- The timeline I will be collecting data is from March 2020 - the start of COVID-19\n"],"metadata":{"id":"gzsU_co0lc4D"}},{"cell_type":"code","source":["def tweet_scraper(start_date):\n","    # Search parameters\n","    key_words = ['#chinesevirus','#StopAAPIHate','#AtlantaShooting','#StopAsianHateCrimes', '#ChinaLiedPeopleDied']\n","    query = ' OR '.join(key_words)+f'since:{start_date}'\n","\n","    # Loop through tweets and build up a pandas dataframe of them\n","    tweet_list = []\n","    \n","    for i, tweet in enumerate(sntwitter.TwitterSearchScraper(query).get_items()):\n","        tweet_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.lang])\n","        if (i+1) % 1000 == 0:\n","            print(f'Finished {i+1} tweets...')    \n","\n","    return pd.DataFrame(tweet_list, columns = ['date', 'tweet_id', 'text', 'user_name', 'reply_count', 'retweet_count', 'like_count', 'language'])"],"metadata":{"id":"kkWaIIV2wdlI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = tweet_scraper('2020-03-01')"],"metadata":{"id":"N140TJ6Byjvu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673801493149,"user_tz":300,"elapsed":1055339,"user":{"displayName":"Khanh Long Nguyen","userId":"01997719433341092319"}},"outputId":"1bdb2c7b-94bc-4caf-c3bf-d7274de853d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-9-fa579edd866b>:10: FutureWarning: content is deprecated, use rawContent instead\n","  tweet_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.replyCount, tweet.retweetCount, tweet.likeCount, tweet.lang])\n"]},{"output_type":"stream","name":"stdout","text":["Finished 1000 tweets...\n","Finished 2000 tweets...\n","Finished 3000 tweets...\n","Finished 4000 tweets...\n","Finished 5000 tweets...\n","Finished 6000 tweets...\n","Finished 7000 tweets...\n","Finished 8000 tweets...\n","Finished 9000 tweets...\n","Finished 10000 tweets...\n","Finished 11000 tweets...\n","Finished 12000 tweets...\n","Finished 13000 tweets...\n","Finished 14000 tweets...\n","Finished 15000 tweets...\n","Finished 16000 tweets...\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:snscrape.modules.twitter:Stopping after 20 empty pages\n"]}]},{"cell_type":"markdown","source":["# Exporting data to .CSV file:"],"metadata":{"id":"R8lyIo3Tmcoe"}},{"cell_type":"code","source":["# df.to_csv('/content/drive/MyDrive/NLP project /data/tweets.csv', encoding='utf-8', index=False)"],"metadata":{"id":"edNMwUiqkBDv"},"execution_count":null,"outputs":[]}]}